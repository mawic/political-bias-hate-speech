{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import of libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "from itertools import islice\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from helper.data_loading import *\n",
    "from helper.preprocessing import *\n",
    "from helper.topic_model_helper import *\n",
    "\n",
    "# Plotting tools\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "#pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "\n",
    "print(\"###### load data ######\")\n",
    "df_org = get_all_germEval_data()\n",
    "df_org = df_org[df_org.label_1 == \"OTHER\"].reset_index(drop=True)\n",
    "\n",
    "print(\"###### prepare splits for 5-fold CV ######\")\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "train_splits = []\n",
    "test_splits = []\n",
    "for train_index, test_index in kf.split(df_org):\n",
    "    train = df_org.iloc[train_index].copy()\n",
    "    test = df_org.iloc[test_index].copy()\n",
    "    \n",
    "    train_splits.append(create_poooling_data(train))#\n",
    "    test_splits.append(create_poooling_data(test))#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the right number of topics\n",
    "'''\n",
    "print(\"###### start 5-fold CV for different k (GENSIM)######\")\n",
    "\n",
    "npmi_score = {'train':[],'test':[]}\n",
    "different_k = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,25,30,35] #range(2, 30, 2)\n",
    "\n",
    "for k in different_k:\n",
    "    npmi_score_cv = {'train':[],'test':[]}\n",
    "    print(\"### Number of topics: {} ###\".format(k))\n",
    "    for i in range(0,5):\n",
    "                \n",
    "        data_train=prepare_data(train_splits[i], preparePoolingData=True)\n",
    "        data_test=prepare_data(test_splits[i], preparePoolingData=True)\n",
    "        \n",
    "        data_train = filter_extremes(data_train.token,no_below=5,no_above=0.1,min_no_token=5)\n",
    "        data_test = filter_extremes(data_test.token,no_below=5,no_above=0.1,min_no_token=5)\n",
    "\n",
    "        write_new_train_test_data(data_train, data_test)     \n",
    "\n",
    "        dict_train, corpus_train, dict_train_fil, corpus_train_fil = create_dict(data_train, None, None, None)\n",
    "        \n",
    "        model = runLDA(dict_train, corpus_train, k,random_state=100)    \n",
    "        topics = get_LDA_topics(model, k, 10)      \n",
    "\n",
    "        ##Evaluate\n",
    "        #npmi\n",
    "        npmi_score_cv[\"train\"].append(calculate_npmi(topics,\"germEval_train\",10))\n",
    "        npmi_score_cv[\"test\"].append(calculate_npmi(topics,\"germEval_test\",10))\n",
    "        \n",
    "        print(\"fold: \",i)\n",
    "        print(\"\\tNPMI (train)\\tNPMI (test)\")\n",
    "        print(\"LDA:\\t{}\\t\\t{}\".format(npmi_score_cv[\"train\"][-1],npmi_score_cv[\"test\"][-1]))\n",
    "       \n",
    "    npmi_score['train'].append(npmi_score_cv[\"train\"])\n",
    "    npmi_score['test'].append(npmi_score_cv[\"test\"])\n",
    "    \n",
    "    #with open('output/npmi_score_gensim.pkl','wb') as f:\n",
    "    #    pickle.dump(npmi_score, f)\n",
    "\n",
    "    print(\"\\nFinal Score:\")\n",
    "    print(\"\\tNPMI (train)\\tNPMI (test)\")\n",
    "    print(\"LDA:\\t{}\\t\\t{}\".format(npmi_score[\"train\"][-1],npmi_score[\"test\"][-1]))\n",
    "\n",
    "print(\"::::FINAL::::\")\n",
    "print(\"train: \",npmi_score[\"train\"])\n",
    "print(\"test: \",npmi_score[\"test\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output/topic_model/npmi_score_gensim.pkl','rb') as f:\n",
    "    npmi_score_gensim = pickle.load(f)\n",
    "    \n",
    "x = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,25,30,35] #range(2, 30, 2)\n",
    "\n",
    "\n",
    "train_score_mean = np.array(list(map(lambda x: statistics.mean(x),npmi_score_gensim[\"train\"])))\n",
    "train_score_stdev = np.array(list(map(lambda x: statistics.stdev(x),npmi_score_gensim[\"train\"])))\n",
    "\n",
    "test_score_mean = np.array(list(map(lambda x: statistics.mean(x),npmi_score_gensim[\"test\"])))\n",
    "test_score_stdev = np.array(list(map(lambda x: statistics.stdev(x),npmi_score_gensim[\"test\"])))\n",
    "\n",
    "#plot npmi score\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "ax.plot(x, test_score_mean, lw=2, label='Test data', color='blue')\n",
    "ax.fill_between(x, test_score_mean+test_score_stdev, test_score_mean-test_score_stdev, facecolor='blue', alpha=0.5)\n",
    "ax.plot(x, train_score_mean, lw=2, label='Train data', color='orange')\n",
    "ax.fill_between(x, train_score_mean+train_score_stdev, train_score_mean-train_score_stdev, facecolor='orange', alpha=0.5)\n",
    "\n",
    "#ax.set_title(r'NPMI score for different k')\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_xlabel('Number of topics (k)')\n",
    "ax.set_ylabel('NPMI score')\n",
    "ax.xaxis.grid(color='gray', linestyle='dashed')\n",
    "\n",
    "plt.grid()    \n",
    "\n",
    "fig.savefig(\"output/figures/topic_model_npmi_score_different_k.svg\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run final Topic Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runLDA(dict_train, corpus_train, k, random_state=100):    \n",
    "       return(gensim.models.ldamodel.LdaModel(corpus=corpus_train,\n",
    "                                           id2word=dict_train,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=random_state,\n",
    "                                           update_every=0,\n",
    "                                           passes=25,  #epochs\n",
    "                                           iterations=2000, #how many iterations the VB is allowed in the E-step/inference without convergence\n",
    "                                           chunksize=10000,\n",
    "                                           eval_every=None,\n",
    "                                           alpha='auto',#'asymmetric',\n",
    "                                           per_word_topics=True)) #callbacks=callbacks\n",
    "    \n",
    "\n",
    "df_all = create_poooling_data(df_org.copy())\n",
    "df_all = prepare_data(df_all, preparePoolingData=True)\n",
    "\n",
    "df_all_filtered = filter_extremes(df_all.token, no_below=5, no_above=0.1, min_no_token=5)\n",
    "write_new_train_test_data(df_all_filtered, df_all_filtered) \n",
    "\n",
    "dict_all, corpus_all, dict_train_fil, corpus_train_fil = create_dict(df_all_filtered, None, None, None)\n",
    "\n",
    "model = runLDA(dict_all, corpus_all, 12,random_state=100)    \n",
    "topics = get_LDA_topics(model, 12, 10)     \n",
    "\n",
    "#print(\"\\tNPMI\\tLog-Perplexity\")\n",
    "#print(\"LDA:\\t{}\\t{}\".format(calculate_npmi(topics,\"germEval_train\",\"10\"),model.log_perplexity(corpus_all)))\n",
    "for topic in topics:\n",
    "    print(\" \".join(topic))\n",
    "    \n",
    "#     NPMI:  Log-Perplexity\n",
    "#LDA: 0.14  -7.7027527852570765\n",
    "\n",
    "'''\n",
    "model.save(\"output/topic_model/model_lda\")\n",
    "dict_all.save(\"output/topic_model/dict\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "df_all = create_poooling_data(df_org.copy())\n",
    "df_all = prepare_data(df_all, preparePoolingData=True)\n",
    "df_all_filtered = filter_extremes(df_all.token,no_below=5,no_above=0.1,min_no_token=5)\n",
    "\n",
    "#load model,dict,create corpus\n",
    "model = gensim.models.ldamodel.LdaModel.load(\"output/topic_model/model_lda\")\n",
    "dictionary = gensim.corpora.Dictionary.load(\"output/topic_model/dict\")\n",
    "corpus = [dictionary.doc2bow(text) for text in df_all_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#visualize and save \n",
    "# set lambda=0.6 for selecting top n words, this improves the coherence for humans \n",
    "# quelle: (https://nlp.stanford.edu/events/illvi2014/papers/sievert-illvi2014.pdf) \n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(model, corpus, dictionary, sort_topics=False)#'mmds','tsne', mds='tsne'\n",
    "#pyLDAvis.save_html(vis, 'output/topic_model/graphic.html')\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top n words with lambda=0.6\n",
    "top_10_words_relevance = [\n",
    "    'venezuela usa brexit sozialismus russland sozialistische maduro einfach sanktionen parlament',\n",
    "    'aksynode16 altkatholisch synode fakt flüchtling antrag menschen neu müssen ring',\n",
    "    'frankfurt blockupy heute solidarität erdogan türkei hbf nonazis morgen kundgebung',\n",
    "    'fcsp schon mehr deutschland ndr gibt wissen bild welt bus',\n",
    "    'sky moin zusammen schönen tag besser verstanden freitag gruppe spielt',\n",
    "    'ard deutschland zdf seehofer m18 merkel tatort mal maaßen israel',\n",
    "    'frau mann immer mal arte leider gesagt folgen dank afd',\n",
    "    'nsu hamburg spd hamburgpride rassismus chemnitz koeln probleme pride etc',\n",
    "    'spd cdu csu grüne fdp hartz hambibleibt hambacherforst merkel toll',\n",
    "   'aachen nazi demo naziwatchac ac1811 antirepac berlin passt repression antifanrw',\n",
    "   'deutschland afd noafd wer sicher immer macht warum angst land',\n",
    "   'deutschland antisemitismus jude israel holocaust judenhass muslime auschwitz vernichtung antisemitische',\n",
    "]\n",
    "top_10_words_relevance = [topic.split() for topic in top_10_words_relevance]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data\n",
    "df_all, hashtag_user, hashtag_user_filtered, single_tw = create_poooling_data(df_org.copy(),getStatsBack=True)\n",
    "df_all = prepare_data(df_all, preparePoolingData=True)\n",
    "df_all_filtered = filter_extremes(df_all.token,no_below=5,no_above=0.1,min_no_token=5)\n",
    "\n",
    "#load model,dict,create corpus\n",
    "model = gensim.models.ldamodel.LdaModel.load(\"output/topic_model/model_lda\")\n",
    "dictionary = gensim.corpora.Dictionary.load(\"output/topic_model/dict\")\n",
    "corpus = [dictionary.doc2bow(text) for text in df_all_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_org_prepared = prepare_data(df_org.copy())\n",
    "other_corpus = list(map(dictionary.doc2bow, df_org_prepared.token))\n",
    "\n",
    "tweet_topic_distribution = get_topic_distribution(model, other_corpus)\n",
    "\n",
    "infereces_assigned_topic = np.argmax(tweet_topic_distribution,axis=1)\n",
    "unique, counts = np.unique(infereces_assigned_topic, return_counts=True)\n",
    "\n",
    "mosted_common_hashtags = {k: v for k, v in sorted(hashtag_user.items(),reverse=True, key=lambda item: item[1])}\n",
    "\n",
    "topics = get_LDA_topics(model, 12, 10) \n",
    "topic_distribution_germEval = list(map(lambda x: round((x/df_org.shape[0]),2),counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total tweets:\\t\\t\\t\\t\",df_org.shape[0])\n",
    "print(\"Total hashtags:\\t\\t\\t\\t\",len(hashtag_user))\n",
    "print(\"Hashtags appearing at least 2 times:\\t\",len(hashtag_user_filtered)-single_tw)\n",
    "print(\"Tweets with no hashtag:\\t\\t\\t\",single_tw)\n",
    "\n",
    "print(\"\\ntop 10 hashtags:\\n\",list(islice(mosted_common_hashtags.items(), 5)))\n",
    "\n",
    "print(\"\\nTotal documents after pooling:\\t\\t\",df_all.shape[0])\n",
    "print(\"Total documents filtered (train data):\\t\",len(df_all_filtered),\"\\n filter: no_below=5, no_above=0.1, min_no_token=5\")\n",
    "\n",
    "print(\"\\n######\\n\\nExample of aggregated documents:\\n #nato\")\n",
    "print(df_all.loc[df_all[\"key\"]==\"#nato\",[\"text\"]].values[0][0])\n",
    "\n",
    "print(\"\\n #lindner\")\n",
    "print(df_all.loc[df_all[\"key\"]==\"#lindner\",[\"text\"]].values[0][0])\n",
    "\n",
    "print(\"\\n######\\n\\nFinal topic model:\\t\\t\\t 12 topics\")\n",
    "print(\"Topic distribution for germEval:\\t\",topic_distribution_germEval)\n",
    "\n",
    "print(\"\\nTop 10 words:\")\n",
    "for i,topic in enumerate(topics):\n",
    "    print(str(i+1)+\"{ \"+\" \".join(topic), \"} Topic size: \",str(int(topic_distribution_germEval[i]*100))+\"%\")\n",
    "    \n",
    "print(\"\\nApply relevance ranking to topic for more readability:\")\n",
    "print(\" formula: lambda*p(w|t) + (1-lambda)*p(w|t)/p(w) with lambda: 0.6\\n\")\n",
    "for i,topic in enumerate(top_10_words_relevance):\n",
    "    print(str(i+1)+\"{ \"+\" \".join(topic), \"}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_distribution_germEval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.autolayout : True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "langs = ['1', '2', '3', '4', '5','6','7','8','9','10','11','12']\n",
    "students = topic_distribution_germEval\n",
    "ax.bar(langs, students)\n",
    "ax.set_xlabel('Topic')\n",
    "ax.set_ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.savefig(\"output/figures/topic_distribution_germEval.svg\", format=\"svg\", bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2",
   "language": "python",
   "name": "tensorflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}