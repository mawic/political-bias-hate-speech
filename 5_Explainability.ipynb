{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import shap\n",
    "shap.initjs()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from helper.data_loading import *\n",
    "from helper.explainability_helper import *\n",
    "\n",
    "germEval = pd.read_pickle('data/GERMEVAL_with_topic_distribution.pkl')\n",
    "germEval = germEval.rename(columns={'label_1': 'label'})\n",
    "\n",
    "germEval_topic_distribution = get_topic_distribution_over_dataset(germEval.loc[germEval.label==\"OTHER\",:])\n",
    "print(\"germEval topic distribution:\\n\",germEval_topic_distribution, \"\\n\")\n",
    "\n",
    "\n",
    "'''\n",
    "# LEFT\n",
    "left = pd.read_pickle('data/LEFT_with_topic_distribution.pkl')\n",
    "left_pool = create_sample_pool(left, germEval_topic_distribution, sample_factor = 5)\n",
    "left = None\n",
    "\n",
    "df_left = get_dataset(left_pool, germEval, germEval_topic_distribution)\n",
    "left_tweets, left_labels = create_train_label(df_left)\n",
    "\n",
    "model_left, word_index_left = train_model(left_tweets, left_labels)\n",
    "\n",
    "model_left.save('output/shap/left_model.h5') \n",
    "\n",
    "with open(\"output/shap/left_dict\",\"wb\") as f:\n",
    "    pickle.dump(word_index_left, f)\n",
    "    \n",
    "with open(\"output/shap/left_df\",\"wb\") as f:\n",
    "    pickle.dump(df_left, f)\n",
    "    \n",
    "\n",
    "# RIGHT\n",
    "right = pd.read_pickle('data/RIGHT_with_topic_distribution.pkl')\n",
    "right_pool = create_sample_pool(right, germEval_topic_distribution, sample_factor = 5)\n",
    "right = None\n",
    "\n",
    "df_right = get_dataset(right_pool, germEval, germEval_topic_distribution)\n",
    "right_tweets, right_labels = create_train_label(df_right)\n",
    "\n",
    "model_right, word_index_right = train_model(right_tweets, right_labels)\n",
    "\n",
    "model_right.save('output/shap/right_model.h5') \n",
    "\n",
    "with open(\"output/shap/right_dict\",\"wb\") as f:\n",
    "    pickle.dump(word_index_right, f)\n",
    "    \n",
    "with open(\"output/shap/right_df\",\"wb\") as f:\n",
    "    pickle.dump(df_right, f)\n",
    "\n",
    "\n",
    "# NEUTRAL\n",
    "neutral = pd.read_pickle('data/NEUTRAL_with_topic_distribution.pkl')\n",
    "neutral_pool = create_sample_pool(neutral, germEval_topic_distribution, sample_factor = 5)\n",
    "neutral = None\n",
    "\n",
    "df_neutral = get_dataset(neutral_pool, germEval, germEval_topic_distribution)\n",
    "neutral_tweets, neutral_labels = create_train_label(df_neutral)\n",
    "\n",
    "model_neutral, word_index_neutral = train_model(neutral_tweets, neutral_labels)\n",
    "\n",
    "model_neutral.save('output/shap/neutral_model.h5') \n",
    "\n",
    "with open(\"output/shap/neutral_dict\",\"wb\") as f:\n",
    "    pickle.dump(word_index_neutral, f)\n",
    "    \n",
    "with open(\"output/shap/neutral_df\",\"wb\") as f:\n",
    "    pickle.dump(df_neutral, f)\n",
    "'''\n",
    "\n",
    "left_model, left_df, left_dict = load_model_dict_data(\"output/shap/left\")\n",
    "right_model, right_df, right_dict = load_model_dict_data(\"output/shap/right\")\n",
    "neutral_model, neutral_df, neutral_dict = load_model_dict_data(\"output/shap/neutral\")\n",
    "\n",
    "germEval = prepare_data(germEval)    \n",
    "germEval = replace_label_to_binary(germEval)\n",
    "germEval_tweet, germEval_labels = create_train_label(germEval)\n",
    "\n",
    "germEval = germEval.filter([\"text\",\"token\",\"label\"])\n",
    "\n",
    "left_germEval_tweet, __ = prepare_data_for_training_single(germEval_tweet, left_dict)\n",
    "right_germEval_tweet, __ = prepare_data_for_training_single(germEval_tweet, right_dict)\n",
    "neutral_germEval_tweet, __ = prepare_data_for_training_single(germEval_tweet, neutral_dict)\n",
    "\n",
    "germEval[\"left_pred\"] = left_model.predict(left_germEval_tweet)\n",
    "germEval[\"right_pred\"] = right_model.predict(right_germEval_tweet)\n",
    "germEval[\"neutral_pred\"] = neutral_model.predict(neutral_germEval_tweet)\n",
    "\n",
    "right_wrong = germEval.loc[(germEval.label == 1) & (germEval.right_pred < 0.5) & ((germEval.left_pred > 0.5) & (germEval.neutral_pred > 0.5))].sort_values(\"right_pred\")\n",
    "left_wrong = germEval.loc[(germEval.label == 1) & (germEval.left_pred < 0.5) & ((germEval.right_pred > 0.5) & (germEval.neutral_pred > 0.5))].sort_values(\"left_pred\")\n",
    "neutral_wrong = germEval.loc[(germEval.label == 1) & (germEval.neutral_pred < 0.5) & ((germEval.right_pred > 0.5) & (germEval.left_pred > 0.5))].sort_values(\"neutral_pred\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at right_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "right_wrong.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIGHT\n",
    "do_explain_model(right_model, right_dict, right_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT\n",
    "do_explain_model(left_model, left_dict, right_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTRAL\n",
    "do_explain_model(neutral_model, neutral_dict, right_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIGHT\n",
    "counter = 0\n",
    "for i, row in right_df.iterrows():\n",
    "     if \"gutmenschen\" in row.token and row.label==0:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT\n",
    "counter = 0\n",
    "for i, row in left_df.iterrows():\n",
    "     if \"gutmenschen\" in row.token and row.label==0:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTAL\n",
    "counter = 0\n",
    "for i, row in neutral_df.iterrows():\n",
    "     if \"gutmenschen\" in row.token and row.label==0:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at neutral_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_wrong.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIGHT\n",
    "do_explain_model(right_model, right_dict, neutral_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT\n",
    "do_explain_model(left_model, left_dict, neutral_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTRAL\n",
    "do_explain_model(neutral_model, neutral_dict, neutral_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at left_wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_wrong.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIGHT\n",
    "do_explain_model(right_model, right_dict, left_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT\n",
    "do_explain_model(left_model, left_dict, left_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTRAL\n",
    "do_explain_model(neutral_model, neutral_dict, left_wrong[:1000], look_first=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIGHT\n",
    "counter = 0\n",
    "for i, row in right_df.iterrows():\n",
    "     if \"heil\" in row.token and row.label==0:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LEFT\n",
    "counter = 0\n",
    "for i, row in left_df.iterrows():\n",
    "     if \"heil\" in row.token and row.label==0:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NEUTAL\n",
    "counter = 0\n",
    "for i, row in neutral_df.iterrows():\n",
    "     if \"heil\" in row.token and row.label==0:\n",
    "            counter += 1\n",
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow1",
   "language": "python",
   "name": "tensorflow1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}